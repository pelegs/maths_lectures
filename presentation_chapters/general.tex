\sectionpic{General Vector Spaces}{../figures/presentation_chapters/general.pdf}
\tikzset{
	operator/.style={circle, inner sep=0pt, minimum size=1cm, text opacity=1, fill opacity=0.5},
	arrow/.style={->, >=stealth},
				}
\pgfkeys{/pgfplots/Axis Style/.style={
    axis x line=middle,
    axis y line=left,
		every axis x label/.style={at={(current axis.right of origin)}, anchor=west},
		every axis y label/.style={at={(axis description cs:0,1)}, anchor=south},
    samples=200,
		xmin=-5, xmax=5,
		ymin=-0.5, ymax=2,
		domain=-5:5,
		axis line style={thick},
		label style={font=\large},
		tick label style={font=\tiny},
		declare function={gauss(\x,\y,\z) = exp(-(\x-\y)^2/(2*\z^2));},
		declare function={func(\x) = gauss(\x, \mu, \sig);},
		declare function={gaussderiv(\x,\y,\z) = -(\x-\y)*gauss(\x,\y,\z)/\z^2;},
		declare function={funcderiv(\x) = gaussderiv(\x, \mu, \sig);},
}}

\begin{frame}
	\frametitle{Properties of $\Rs{n}$}
	Let us review some properties of the space $\Rs{n}$, some of them we already used implicetly without giving them too much thought.
\end{frame}

\begin{frame}
	\frametitle{Properties of $\Rs{n}$}
	\only<1-6>{Relating to vector-vector addition}\only<7->{Relating to scalar-vector product}:
	\begin{itemize}
			\only<1>{
				\item The addition of any two vectors $\vec{u},\vec{v}\in\Rs{n}$ yields a vector $\vec{w}=\vec{u}+\vec{v}$ that is also in $\Rs{n}$.
					\vspace{5mm}
					\begin{presentation_example}
						For $\vec{u}=\colvec{3}{1}{2}{-1}$ and $\vec{v}=\colvec{3}{-1}{3}{0}$ (both in $\Rs{3}$),
						\begin{equation*}
							\vec{w} = \vec{u}+\vec{v} = \colvec{3}{0}{5}{-1}\in\Rs{3}.
						\end{equation*}
					\end{presentation_example}
			}
			\only<2>{
			\item Vector addition is commutative: $\vec{v}+\vec{u}=\vec{u}+\vec{v}$.
					\vspace{5mm}
					\begin{presentation_example}
						For the same vectors as before:
						\begin{align*}
							\vec{u}+\vec{v} &= \colvec{3}{1}{2}{-1} + \colvec{3}{-1}{3}{0} = \colvec{3}{1+(-1)}{2+3}{-1+0} = \colvec{3}{0}{5}{-1}.\\
							\vec{v}+\vec{u} &= \colvec{3}{-1}{3}{0} + \colvec{3}{1}{2}{-1} = \colvec{3}{-1+1}{3+2}{0+(-1)} = \colvec{3}{0}{5}{-1}.
						\end{align*}
					\end{presentation_example}
			}
			\only<3-4>{
			\item Vector addition is assosiative: $\vec{v}+\left(\vec{u}+\vec{w}\right)=\left(\vec{u}+\vec{v}\right)+\vec{w}$.
					\vspace{5mm}
					\begin{presentation_example}
						For $\vec{a}=\colvec{2}{1}{0},\ \vec{b}=\colvec{2}{0}{-1},\ \vec{c}=\colvec{2}{3}{1}$:
						\begin{align*}
							\only<3>{
								\vec{a}+\left(\vec{b}+\vec{c}\right) &= \colvec{2}{1}{0} + \left[ \colvec{2}{0}{-1} + \colvec{2}{3}{1} \right]\\
								&= \colvec{2}{1}{0} + \colvec{2}{3}{0} = \colvec{2}{4}{0}.
							}
							\only<4>{
								\left(\vec{a}+\vec{b}\right)+\vec{c} &= \left[ \colvec{2}{1}{0} + \colvec{2}{0}{-1} \right] + \colvec{2}{3}{1}\\
								&= \colvec{2}{1}{-1} + \colvec{2}{3}{1} = \colvec{2}{4}{0}.
							}
						\end{align*}
					\end{presentation_example}
			}
			\only<5>{
			\item The zero vector $\vec{0}$ is unique and has the property that $\vec{v}+\vec{0} = \vec{v}$ for any vector $\vec{v}\in\Rs{n}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{equation*}
							\colvec{6}{4}{-1}{0}{3}{-6}{2} + \colvec{6}{0}{0}{0}{0}{0}{0} = \colvec{6}{4}{-1}{0}{3}{-6}{2}.
						\end{equation*}
					\end{presentation_example}
			}
			\only<6>{
			\item Any vector $\vec{v}\in\Rs{n}$ has an opposite vector $\left( -\vec{v} \right)\in\Rs{n}$ such that $\vec{v}+\left( -\vec{v} \right)=\vec{0}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{equation*}
							\colvec{6}{4}{-1}{0}{3}{-6}{2} + \colvec{6}{-4}{1}{0}{-3}{6}{-2} = \colvec{6}{0}{0}{0}{0}{0}{0}.
						\end{equation*}
					\end{presentation_example}
			}
			\only<7>{
			\item Any scale by $\alpha\in\mathbb{R}$ of a vector $\vec{v}\in\Rs{n}$ is also in $\Rs{n}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{equation*}
							-3\cdot\colvec{7}{1}{-1}{2}{0}{-1}{3}{-2} = \colvec{7}{-3}{3}{-6}{0}{3}{-9}{6}.
						\end{equation*}
					\end{presentation_example}
			}
			\only<8>{
			\item Any scale by $\alpha\in\mathbb{R}$ of a vector $\vec{v}\in\Rs{n}$ is also in $\Rs{n}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{equation*}
							-3\cdot\colvec{7}{1}{-1}{2}{0}{-1}{3}{-2} = \colvec{7}{-3}{3}{-6}{0}{3}{-9}{6}.
						\end{equation*}
					\end{presentation_example}
			}
			\only<9>{
			\item Scalar-vector multiplication is associative: $\alpha\left( \beta\vec{v} \right) = \left( \alpha\beta \right)\vec{v}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{align*}
							-3\left[ 2\colvec{3}{1}{-4}{5} \right] &= -3\colvec{3}{2}{-8}{10} = \colvec{3}{-6}{24}{-30}\\
							\left( -3\cdot2 \right)\colvec{3}{1}{-4}{5} &= -6\colvec{3}{1}{-4}{5} = \colvec{3}{-6}{24}{-30}.
						\end{align*}
					\end{presentation_example}
			}
			\only<10>{
			\item Scalar-vector multiplication is distributive in respect to scalar addition: $\left( \alpha+\beta \right)\vec{v} = \alpha\vec{v} + \beta\vec{v}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{align*}
							(5-2)\colvec{3}{2}{-1}{0} &= 3\colvec{3}{2}{-1}{0} = \colvec{3}{6}{-3}{0}.\\
							5\colvec{3}{2}{-1}{0} - 2\colvec{3}{2}{-1}{0} &= \colvec{3}{10}{-5}{0} - \colvec{3}{4}{-2}{0} = \colvec{3}{6}{-3}{0}.
						\end{align*}
					\end{presentation_example}
			}
			\only<11>{
			\item Scalar-vector multiplication is distributive in respect to vector addition: $\alpha\left( \vec{v}+\vec{u} \right) = \alpha\vec{v} + \alpha\vec{u}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{align*}
							5\left[ \colvec{3}{1}{-1}{3} + \colvec{3}{0}{2}{-1}\right] &= 5\colvec{3}{1}{1}{2} = \colvec{3}{5}{5}{10}.\\
							5\colvec{3}{1}{-1}{3} + 5\colvec{3}{0}{2}{-1} &= \colvec{3}{5}{-5}{15} + \colvec{3}{0}{10}{-5} = \colvec{3}{5}{5}{10}.
						\end{align*}
					\end{presentation_example}
			}
			\only<12>{
			\item The scalar $\alpha=1$ is neutral in respect to scalar-vector products: $1\vec{v} = \vec{v}$.
					\vspace{5mm}
					\begin{presentation_example}
						\begin{equation*}
							1\colvec{7}{1}{3}{2}{6}{-5}{7}{-4} = \colvec{7}{1}{3}{2}{6}{-5}{7}{-4}.
						\end{equation*}
					\end{presentation_example}
			}
	\end{itemize}
%				\onslide<12>{\item The scalar $\alpha=1$ is neutral in scalar-vector products: $1\vec{v}=\vec{v}$.}
\end{frame}

\begin{frame}
	\frametitle{Abstract Vector Spaces}
	These properties are somewhat obvious on $\Rs{n}$. However, many times it is worthwhile to use more abstract vector spaces, which can help us model diverse physical and theoretical systems, since once a construct behaves as a vector space, it is a relatively simple process to apply to it all the analysis tools learned so far.

	We will not bother here with the formal definition of a vector space\footnote{For such definition, see here: \href{http://www.math.niu.edu/~beachy/courses/240/06spring/vectorspace.html}{http://www.math.niu.edu/~beachy/courses/240/06spring/vectorspace.html}.}, but look at one example, which we will later expand on: the space of all real functions $\func{f}{\mathbb{R}}{\mathbb{R}}$.
\end{frame}

\begin{frame}
	\frametitle{Real Functions as a Vector Space}
	\begin{itemize}
			\onslide<2-6>{\item For any two real functions $f(x),g(x)$ the addition $(f+g)(x)=f(x)+g(x)$ is also a real function.}
			\onslide<3-6>{\item The addition of two real functions is commutative: $(f+g)(x)=f(x)+g(x)=g(x)+f(x)=(g+f)(x)$.}
		\onslide<4-6>{\item This addition is also associative: $xxx$.}
		\onslide<5-6>{\item The function $z(x)=0$ is the zero function, since for any other real function $f(x)$,
			\begin{equation*}
				(f+z)(x) = f(x)+z(x) = f(x)+0 = f(x).			
		\end{equation*}}
		\onslide<6>{\item For each real function $f(x)$ there exists an opposite function $(-f)(x)=-f(x)$, for which
			\begin{equation*}
				f(x)+\left(-f(x)\right)=f(x)-f(x)=0=z(x).
		\end{equation*}}
	\end{itemize}
\end{frame}

%------------------%
%    COMPONENTS    %
%------------------%

\begin{frame}
	\frametitle{Components (temp name)}
	Recall that a vector in $\Rs{n}$ can be written using its component in any basis, e.g. the standard basis vectors $\left\{ \eb{1},\eb{2},\dots,\eb{n} \right\}$:
	\begin{align*}
		\vec{v} &= v_{1}\eb{1} + v_{2}\eb{2} + \cdots + v_{n}\eb{n}\\
		&= \sum\limits_{i=1}^{n}v_{i}\eb{i}.
	\end{align*}

	How can we "decompose" a function in a similar way?

	For this purpose, the \emph{Dirac delta function} comes in handy.
\end{frame}

\begin{frame}
	\frametitle{The Dirac Delta Function}
	Loosely speaking, we can define the Dirac delta function as
	\begin{equation*}
		\delta(x)=
		\begin{cases}
			\infty, & x=0\\
			0, & x\neq0.
		\end{cases}
	\end{equation*}

	\centering
	\begin{tikzpicture}
		\begin{axis}[
				Axis Style,
				axis line style={<->, stealth-stealth, thick},
				axis y line=none,
				xmin=-2, xmax=2,
				ymin=-1, ymax=1,
				xtick={-2,-1,...,2},
			]
			\path[draw=col1, very thick, dashed] (axis cs:0,0) to (axis cs:0,2);
		\end{axis}
	\end{tikzpicture}
\end{frame}

\begin{frame}
	\frametitle{The Dirac Delta Function}
We can then define infinitaly many dirac functions, for each point $\tilde{x}\in\mathbb{R}$:
\begin{equation*}
	\delta_{\tilde{x}}(x) = \delta(x-\tilde{x}).
\end{equation*}

	\vspace{1cm}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				Axis Style,
				axis line style={<->, stealth-stealth, thick},
				axis y line=none,
				xmin=-2, xmax=2,
				ymin=0, ymax=3,
				xtick={-2,-1,...,2},
			]
			\path[draw=col1, very thick, dashed] (axis cs:0,0) to (axis cs:0,1.5) node [col1, above] {$\delta_{0}(x)$};
			\path[draw=col2, very thick, dashed] (axis cs:1,0) to (axis cs:1,1.5) node [col2, above] {$\delta_{1}(x)$};
			\path[draw=col3!75!black, very thick, dashed] (axis cs:-0.75,0) to (axis cs:-0.75,1.5) node [col3!75!black, above] {$\delta_{-\frac{3}{4}}(x)$};
			\path[draw=col4, very thick, dashed] (axis cs:pi/2,0) to (axis cs:pi/2,1.5) node [col4, above] {$\delta_{\frac{\pi}{2}}(x)$};
			\path[draw=col5, very thick, dashed] (axis cs:-1.6,0) to (axis cs:-1.6,1.5) node [col5, above] {$\delta_{-1.6}(x)$};
		\end{axis}
	\end{tikzpicture}
\end{frame}

\begin{frame}
	\frametitle{Spanning a Function Space}
	Using the Dirac delta function, we can now decompose a function to its components in a similar way we did with vectors:
	\begin{align*}
		\vec{v} & =\sum\limits_{i=1}^{n}v_{i}\eb{i}\\
		&\Downarrow\\
		f(x) &= \text{to do}.
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{Dot Product of Two Functions}
	Recall the definition of a dot product of two vectors $\vec{u}$ and $\vec{v}$:
	\begin{align*}
		\langle \vec{u}, \vec{v} \rangle &= u_{1}v_{1} + u_{2}v_{2} + \cdots + v_{n}u_{n}\\
		&= \sum\limits_{i=1}^{n} u_{i}v_{i}.
	\end{align*}

	The dot product of two functions $f(x), g(x)$ on the interval $\left[ a,b \right]$ can be similarily defined:
	\begin{equation*}
		\langle f(x), g(x) \rangle = \int\limits_{a}^{b} f(x)g(x) \dif x.
	\end{equation*}
\end{frame}

\begin{frame}
	\frametitle{Dot Product of Two Functions}
	\begin{presentation_note}
		\only<1>{
			Over $\mathbb{C}^{n}$, the dot product of two vectors $\vec{u}, \vec{v}$ is defined as
			\begin{align*}
				\langle \vec{u}, \vec{v} \rangle &= \bar{u}_{1}v_{1} + \bar{u}_{2}v_{2} + \cdots + \bar{u}_{n}v_{n}\\
				&= \sum\limits_{i=1}^{n}\bar{u}_{i}v_{i},
			\end{align*}
			where $\bar{z}$ is the \emph{complex conjugate} of $z$. For a real number $x$, $\bar{x}=x$ - i.e. real numbers are their own complex conjugates.
		}

		\only<2>{
			The definition of a dot product of two complex functions $f(z), g(z)$ is similar:
			\begin{equation*}
				\langle f(z), g(z) \rangle = \int\limits_{\Omega}\bar{f}(z)g(z) \dif z,
			\end{equation*}
			where $\Omega$ is the space over which the integration is done.
			
			\vspace{5mm}
			Sometimes, especially in physics, the complex conjugate of a function $f(z)$ is denoted as $f^{*}(z)$.
		}
	\end{presentation_note}
\end{frame}

\begin{frame}
	\frametitle{Dot Product of Two Functions}
	If the dot product of two functions $f(x), g(x)$ is zero, we say that the functions are \emph{orthogonal} (just as with vectors).

	\begin{presentation_example}
		The functions $f(x)=x, f(x)=x^{2}$ are orthogonal over the entire real line, since
		\begin{equation*}
			\langle x, x^{2} \rangle = \int\limits_{-\infty}^{\infty} x\cdot x^{2} \dif x = \int\limits_{-\infty}^{\infty}x^{3} \dif x = 0.
		\end{equation*}
		(recall that integrals over the real line of anti-symmetric functions, such as $x^{3}$, always equal $0$)
	\end{presentation_example}
\end{frame}

\begin{frame}
	\frametitle{Norm of Functions}
	The \emph{norm} of a function $f$ over an interval $\left[ a,b \right]$ can be defined as
	\begin{equation*}
		\norm{f} = \sqrt{\langle f, f \rangle} = \sqrt{\int\limits_{a}^{b} f^{2}(x) \dif x}.
	\end{equation*}

	\begin{presentation_example}
		The norm of $f(x)=-x^{2}$ on $\left[ -2,2 \right]$ is
		\begin{align*}
			\norm{f} &= \sqrt{\int\limits_{-2}^{2} \left(-x^{2}\right)^{2} \dif x} = \sqrt{2\int\limits_{0}^{2} x^{4} \dif x}\\
			&= \sqrt{\left.\frac{2}{5}x^{5}\right|_{0}^{2}} = \sqrt{\frac{2}{5}\left( 32 - 0 \right)} = \frac{8}{\sqrt{5}} \approx 3.578.
		\end{align*}
	\end{presentation_example}
\end{frame}

\begin{frame}
	\frametitle{Norm of Functions}
	A function that has a norm of $1$ is said to be \emph{normalized}.

	\begin{presentation_example}
		The \emph{Gaussian distribution}
		\begin{equation*}
			\mathcal{G}(x) = e^{-\frac{x^{2}}{2}}
		\end{equation*}
		has a \textbf{squared} norm
		\begin{align*}
			\norm{\mathcal{G}}^{2} &= \int\limits_{-\infty}^{\infty}\left(e^{-\frac{x^{2}}{2}}\right)^{2}\dif x = \int\limits_{-\infty}^{\infty}e^{-\cancel{2}\frac{x^{2}}{\cancel{2}}}\dif x = \int\limits_{-\infty}^{\infty}e^{-x^{2}}\dif x = \sqrt{\pi}.\\
		\end{align*}
	\end{presentation_example}
\end{frame}
